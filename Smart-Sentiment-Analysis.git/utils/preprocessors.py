import re
import string

class Preprocessing():

    # Input: string
    # Output: processed_string

    def __init__(self, stopwords_path, annotator_path):
        with open(stopwords_path, 'r', encoding='utf-8') as f:
            self.stopwords = [line.strip() for line in f.readlines()]

        from vncorenlp import VnCoreNLP
        self.annotator = VnCoreNLP(annotator_path, annotators="wseg,pos,ner,parse", max_heap_size='-Xmx2g')

    @staticmethod
    def clean_text(text):
        text = text.lower()
        text = re.sub("[%s]" % re.escape(string.punctuation), " ", text)
        return text

    def stop_word_remove(self, text):
        words = re.findall(r'\w+', text)
        filtered_words = [word for word in words if word not in self.stopwords or word == "kh√¥ng"]
        filtered_text = ' '.join(filtered_words)
        return filtered_text

    @staticmethod
    def remove_number( text):
        return re.sub(r'\d+', ' ', text)

    @staticmethod
    def remove_special_char(string):
        # Removing characters that are neither alphanumeric nor basic punctuations,
        # but preserving Vietnamese diacritics.
        cleaned_string = re.sub(
            r"[^a-zA-Z0-9.,!? √°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒëƒê ]", '', string)
        return cleaned_string

    @staticmethod
    def replace_abbreviations(text):
        # Creating a dictionary to store abbreviation mappings
        abbreviations = {
            r'\bks\b': 'kh√°ch s·∫°n',
            # The \b ensures we match whole words only, avoiding replacements in the middle of words
            r'\bnv\b': 'nh√¢n vi√™n',

            r'\bko\b': 'kh√¥ng',

            r'\bdc\b': 'ƒë∆∞·ª£c',

            r'\bƒëc\b': 'ƒë∆∞·ª£c',

            r'\btk\b': 't√†i kho·∫£n',

            r'\bh\b': 'gi·ªù'
        }

        # Looping through the dictionary to replace all abbreviations
        for abbr, full_form in abbreviations.items():
            text = re.sub(abbr, full_form, text, flags=re.IGNORECASE)

        return text

    def segment(self, text):
        annotated_text = self.annotator.annotate(text)
        segmented_sentence = " ".join([word['form'] for sentence in annotated_text['sentences'] for word in sentence])
        return segmented_sentence

    def process(self, text):
        text = self.clean_text(text)
        text = self.remove_number(text)
        text = self.remove_special_char(text)
        text = self.replace_abbreviations(text)
        text = self.segment(text)
        text = self.stop_word_remove(text)
        return text

if __name__ == '__main__':
    preprocessor = Preprocessing('../data/external/vietnamese-stopwords-dash.txt',
                                 './libs/vncorenlp/VnCoreNLP-1.2.jar')
    text = 'ƒêi·ªÉm mua s·∫Øm qu√† l∆∞u ni·ªám l√Ω t∆∞·ªüng, ƒë·∫ßy ƒë·ªß h√†ng h√≥a c·ªßa c√°c l√†ng ngh·ªÅ truy·ªÅn th·ªëng c·ªßa v√πng qu√™ ƒë·∫•t v√µ T√¢y S∆°n, B√¨nh ƒê·ªãnh. N∆°i ƒë√¢y l√† ƒëi·ªÉm cung ·ª©ng h√†ng h√≥a c·ªßa ng∆∞·ªùi n√¥ng d√¢n n√™n gi√° c≈©ng r·∫•t b√¨nh d√¢n. H√£y ƒë·∫øn ƒë√¢y khi ƒë·∫øn v·ªõi B√¨nh ƒê·ªãnh, v√¨ kh√¥ng mu·ªën khi v·ªÅ qu√™n mang theo m√≥n ƒë·∫∑c s·∫£n truy·ªÅn th·ªëng, tinh hoa c·ªßa ƒë·∫•t v√µ T√¢y S∆°n üòç'
    text = preprocessor.process(text)
    print(text)